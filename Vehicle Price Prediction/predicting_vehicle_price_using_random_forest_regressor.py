# -*- coding: utf-8 -*-
"""Predicting vehicle price using Random Forest regressor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Wz12dIEBM9GNROhQxbub6E-14QCD22y
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder

data = pd.read_csv("vehicle_price_dataset.csv")

print(data.head())

numeric_cols = data.select_dtypes(include=[np.number]).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())

categorical_cols = data.select_dtypes(include=['object']).columns
for col in categorical_cols:
    data[col] = data[col].fillna(data[col].mode()[0])

label_encoder = LabelEncoder()
for col in categorical_cols:
    data[col] = label_encoder.fit_transform(data[col])

X = data.drop("price", axis=1)
y = data["price"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=None,
    random_state=42
)

rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("Model Evaluation:")
print("MAE :", mae)
print("MSE :", mse)
print("RMSE:", rmse)
print("RÂ²  :", r2)

df = pd.read_csv('vehicle_price_dataset.csv')


new_vehicle = {
    'year': 2022, 'engine_size': 1.5, 'mileage': 25000,
    'fuel_type': 'Petrol', 'transmission': 'Manual', 'brand': 'Hyundai'
}

mapped_new_vehicle_data = {
    'year': new_vehicle.get('year'),
    'mileage': new_vehicle.get('mileage'),
    'fuel': new_vehicle.get('fuel_type'),
    'transmission': new_vehicle.get('transmission'),
    'make': new_vehicle.get('brand'),
}

original_numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('price', errors='ignore').tolist()
original_categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

# Create a dictionary for the new vehicle data, filling in missing columns with defaults from `df`
full_new_vehicle_data = {}
for col in X.columns:  # Iterate through the columns that the model expects (from X, the training features)
    if col in mapped_new_vehicle_data and mapped_new_vehicle_data[col] is not None:
        full_new_vehicle_data[col] = mapped_new_vehicle_data[col]
    elif col in original_numeric_cols:
        # Use median from original training data for numerical defaults
        full_new_vehicle_data[col] = df[col].median()
    elif col in original_categorical_cols:
        # Use mode from original training data for categorical defaults
        full_new_vehicle_data[col] = df[col].mode()[0]
    else:
        # for any unexpected columns
        full_new_vehicle_data[col] = None

new_data_for_prediction = pd.DataFrame([full_new_vehicle_data])[X.columns.tolist()]

for col in original_categorical_cols:
    if col in new_data_for_prediction.columns:
        le_for_new_data = LabelEncoder()
        # Combine categories from original df and new data to fit the encoder
        # This handles cases where new_data_for_prediction might introduce unseen labels
        all_categories = pd.concat([df[col], new_data_for_prediction[col]]).astype(str).unique()
        le_for_new_data.fit(all_categories)
        new_data_for_prediction[col] = le_for_new_data.transform(new_data_for_prediction[col].astype(str))

predicted_price = rf_model.predict(new_data_for_prediction)

print("Predicted Vehicle Price:", predicted_price[0])