# -*- coding: utf-8 -*-
"""CREDIT_CARD_FRAUD_TRANSACTION_DETECTION (final).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lRvs2clj5wzDuFmGCWNiGSDryxZ2HHAx
"""

import pandas as pd
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import gridspec

"""**LOADING DATASET AND VIEWING THE DATA**


"""

# Load the Dataset
data = pd.read_csv("creditcard.csv")

#displaying the dataset
print(data.head())

#discribing the data
print(data.shape)
print(data.describe())

"""**DATA PREPROCESSING**"""

# Drop rows where 'Class' is NaN
data = data.dropna(subset=['Class'])
#remove rows from a DataFrame where the value in the Class column is missing (NaN)

from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = data.drop('Class', axis=1)
y = data['Class']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""
x = feature matrix(independent variables)
y = target vector(dependent variable)
train_test_split = splits the dataset into two subsets one for training the model and one for testing the model's performance
test_size=0.2 = 20% of the data will be allocated to the test set, and the remaining 80% will be used for training.
random_state=2 = This is the seed for the random number generator, which controls the shuffling of the data before splitting. Setting the random_state ensures that the split
                 is reproducible, meaning you'll get the same train-test split every time you run the code with that seed. If you omit it, you might get a different split each time.

"reproducible" refers to the ability to generate the exact same results each time the code is executed. This is particularly important for tasks like model training and evaluation,
where consistency is key for debugging, comparison, and results verification.

X_train: This contains the features for the training set.
X_test: This contains the features for the test set.
Y_train: This contains the labels for the training set.
Y_test: This contains the labels for the test set.
"""

"""**VISUALIZATION OF DATA USING HEATMAP**"""

corrmat = data.corr()
#correlation matrix gives you a way to see the relationships between multiple variables at once.
fig = plt.figure(figsize = (12, 9))
#corrmat - variable contains the correlation coefficients between all pairs of numerical columns in your data DataFrame.
#vmax - parameter controls the maximum value for the color scale (color intensity) in the heatmap.
#square - parameter forces the heatmap to have square-shaped cells, making the rows and columns equally spaced
sns.heatmap(corrmat, vmax = .8, square = True)
plt.show()

"""**DATA SCALING**"""

#fit - methods helps in fitting the data into a modal
#trasnform - methods help in transforming the data into a form that is more suitable for modal
#fit_transform - combination of both fit and trasform

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Scaling the data is an important preprocessing step for the KNN algorithm because the algorithm is distance-based.
#If the data is not scaled, features with larger scales will dominate the distance calculation and can result in incorrect classifications.

"""**MODEL TRAINING AND EVALUATION**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

model = KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Print classification report
# used to evaluate the performance of a classification model.
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Print accuracy score
print("Accuracy Score: ", accuracy_score(y_test, y_pred))

# Precision is the ratio of correctly predicted positive observations to the total predicted positives
# Recall is the ratio of correctly predicted positive observations to the total actual positives.
# F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.
# Support is the number of actual occurrences of the class in the dataset.
# Accuracy is the ratio of correct predictions (both true positives and true negatives) to the total number of predictions.

"""**CONFUSTION MATRIX AND VISUALIZATION**"""

from sklearn.metrics import confusion_matrix

#A confusion matrix is a tool used to evaluate the performance of a classification model

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

#annot - argument adds annotations inside each cell of the heatmap
#fmt - argument specifies the formatting of the annotations.
#      'd' stands for decimal integer format, so the numbers in the heatmap will be displayed as integers